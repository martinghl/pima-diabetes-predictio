# Pima Indians Diabetes – Clinical Prediction Models

This repository contains a fully reproducible analysis of the **Pima Indians Diabetes** dataset from the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK). The goal is to build and compare several clinical prediction models for type 2 diabetes using routinely collected clinical measurements.

## 1. Repository structure

```text
pima-diabetes-prediction/
├─ README.md
├─ requirements.txt
├─ .gitignore
├─ data/
│   └─ pima-indians-diabetes.csv
├─ src/
│   └─ health_data_analysis.py
├─ reports/
│   ├─ analysis_steps.md
│   └─ report.md
└─ figures/
```

- `data/`: raw dataset (CSV).
- `src/health_data_analysis.py`: main analysis script (data loading, cleaning, modelling, plotting).
- `reports/analysis_steps.md`: detailed step-by-step analysis including code and outputs.
- `reports/report.md`: short written report describing the real-world task and findings.
- `figures/`: plots generated by the analysis script.

## 2. Data

The dataset used is the **Pima Indians Diabetes dataset**, containing 768 records on Pima Indian women aged ≥ 21 years, with eight clinical features (e.g., glucose, BMI, blood pressure) and a binary outcome indicating diabetes. Place the CSV file at:

```text
data/pima-indians-diabetes.csv
```

If you do not have the file locally, you can download it from common machine-learning repositories (e.g. UCI, Kaggle) and save it under that path.

## 3. Installation

It is recommended to use a virtual environment:

```bash
git clone <YOUR_REPO_URL>.git
cd pima-diabetes-prediction

python -m venv .venv
source .venv/bin/activate      # Windows: .venv\Scripts\activate

pip install --upgrade pip
pip install -r requirements.txt
```

## 4. Usage

Run the full pipeline (data loading, cleaning, model training, evaluation, and plotting):

```bash
python -m src.health_data_analysis \
    --data data/pima-indians-diabetes.csv \
    --outdir .
```

By default this will:

- Clean the dataset (handle zero-as-missing values).
- Train four models:
  - Logistic regression
  - Random forest
  - XGBoost
  - Neural network (MLP)
- Print performance metrics to the console.
- Save:
  - `metrics.csv` and `metrics.json` in the output directory.
  - Plots into the `figures/` folder:
    - `outcome_distribution.png`
    - `correlation_heatmap.png`
    - `confusion_matrix_<model>.png`
    - `feature_importance_<model>.png` (for tree/boosting models)

You can change the output directory:

```bash
python -m src.health_data_analysis --outdir outputs
```

## 5. Reproducibility notes

- The script fixes `random_state=42` for all models to improve reproducibility.
- All preprocessing (cleaning, scaling, train/test split) happens inside the script using the same random seed.
- The code is self-contained and relies only on packages listed in `requirements.txt`.

## 6. Reports

- `reports/analysis_steps.md` – detailed step-by-step narrative with code and outputs.
- `reports/report.md` – concise narrative report describing the task, methods, and findings.

Both reports are plain Markdown and can be viewed directly on GitHub.

